Variance gives the spread of values around the [[Expected Value or Expectation]]. Variance is important because it gives context on how small or large each value is. For example, if I have 2 [[Random Variables]] with two different [[Probability Mass Function]] , the spread between each possible value of 1 PMF is greater than the second. In other words, the mean for both PMFs might be the same, but the values of one PMF lie farther or closer than the other PMF

The formula of variance $Var(X)$ is: 

$$E[X^2] - (E[X])^2$$

This means we must find the square of each value $X$ takes on and find its expected value (i.e.: replace $x_i$ in the expectation formula with $x_i^2$ ), square the expected value of $X$ , and subtract the latter from the former.

Variance can give out numbers that are very spread apart and not intuitive to understand. By taking the square root of variance, we get the standard deviation, or an average of how spread apart values are from the mean.

